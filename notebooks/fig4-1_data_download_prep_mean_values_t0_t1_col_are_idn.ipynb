{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b102a18d-8da0-4d78-b9ad-c906a74d52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import duckdb\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a4cb9d7-e0da-4e82-ba4c-e26db6ce83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idn = duckdb.read_parquet(r\"D:\\corporate_extended\\IDN_data\\IDN_data\\h3_cell_id=*\\*.parquet\", hive_partitioning=1)\n",
    "\n",
    "col = duckdb.read_parquet(r\"D:\\corporate_extended\\COL_data\\COL_data\\h3_cell_id=*\\*data_0.parquet\", hive_partitioning=1)\n",
    "\n",
    "are = duckdb.read_parquet(r\"C:\\Users\\Lilly\\Downloads\\ARE_data\\ARE_data\\h3_cell_id=*\\*.parquet\", hive_partitioning=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afdd0960-1cd7-4083-95b9-edbdd97f0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All corporate Hashtags\n",
    "hashtag_list = ['amap', 'adt', 'bolt', 'DigitalEgypt', 'expedia', 'gojek', 'MSFTOpenMaps', 'grab', 'Kaart', 'Kontur', 'mbx', 'RocketData',\n",
    "                'disputed_by_claimed_by', 'Snapp', 'stackbox', 'Telenav', 'Lightcyphers', 'tomtom', 'TIDBO', 'WIGeoGIS-OMV', 'نشان',\n",
    "                'mapbox', 'Komoot', 'AppLogica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "012bd95f-f9cf-4ec2-ace9-cbb78bbfd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user-ids in working format\n",
    "def getListID(filename):\n",
    "    df = dataframes_dict[filename]\n",
    "    CorpoId = df['User ID']\n",
    "    user_ids_str = ','.join([f\"'{id}'\" for id in CorpoId])\n",
    "    return user_ids_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba205247-5f27-44d8-bcad-78ef2b7407c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where your Excel files are located\n",
    "directory_path =  r\"C:\\Users\\lilly\\Documents\\bachelorarbeit\\analysis\\UserNameID-v2\"\n",
    "\n",
    "# Get a list of all Excel files in the directory\n",
    "excel_files = glob.glob(os.path.join(directory_path, \"*.xls\"))\n",
    "\n",
    "# Create an empty dictionary to store DataFrames\n",
    "dataframes_dict = {}\n",
    "\n",
    "# Read each Excel file and store its DataFrame in the dictionary - files saved as xldr - otherwise when saved as csv, other method applicable\n",
    "for excel_file in excel_files:\n",
    "    filename = os.path.basename(excel_file)\n",
    "    df = pd.read_csv(excel_file) \n",
    "    dataframes_dict[filename] = df\n",
    "\n",
    "Meta = getListID(\"MetaUser.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f74ff93-ad17-4aad-9ae7-15460b79511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ce_statement_meta(hashtags_list):\n",
    "    # Construct the dynamic CE statement based on the list of hashtags including the user ids form Meta\n",
    "    ce_statement = \" OR \".join([f\"hashtags ILIKE '%{tag}%'\" for tag in hashtags_list]) + f\"OR user_id IN ({Meta})\"\n",
    "    return ce_statement\n",
    "\n",
    "def generate_nonce_statement_meta(hashtags_list): \n",
    "    # Construct the dynamic nonCE statement based on the list of hashtags including the user ids form Meta\n",
    "    non_ce_statement = \" AND \".join([f\"hashtags NOT ILIKE '%{tag}%'\" for tag in hashtags_list]) + f\"AND user_id NOT IN ({Meta})\"\n",
    "    return non_ce_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dddaa64-7825-42d6-b1c3-18e472a3be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_where_corpo = generate_ce_statement_meta(hashtag_list)\n",
    "\n",
    "meta_where_non_corpo = generate_nonce_statement_meta(hashtag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67070af1-875a-4985-81ad-05831ac40058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_string(df):\n",
    "    hex_id_str = ','.join([f\"'{id}'\" for id in df['h3_cell_id']])\n",
    "    return hex_id_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92b032b5-5071-4f01-ac13-240613e83548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get a combined time column \n",
    "def addTime(df):\n",
    "\n",
    "    df[\"time\"] = df[\"year\"].astype(str) + '-' + df[\"month\"].astype(str)\n",
    "    df['time'] = pd.to_datetime(df['time'], format='%Y-%m')\n",
    "    \n",
    "    df['time'] = df['time'].dt.to_period('M')\n",
    "\n",
    "    dfYear = df.drop(columns=[\"year\", \"month\"])\n",
    "    \n",
    "    return dfYear\n",
    "\n",
    "def Edits_monthly(db, where_statement, corporate_list, new_column_name):\n",
    "    # Edits either corporate or non-corporate depending on the where statement\n",
    "    monthly = f\"\"\"\n",
    "        SELECT year, month, COUNT(*) AS totalEdits, h3_cell_id AS name\n",
    "        FROM {db}\n",
    "        WHERE ({where_statement}) AND h3_cell_id IN ({corporate_list}) AND year > 2014\n",
    "        GROUP BY month, year, h3_cell_id\n",
    "        ORDER BY year, month ASC\n",
    "    \"\"\"\n",
    "\n",
    "    result = duckdb.sql(monthly)\n",
    "    \n",
    "    df = result.to_df()\n",
    "\n",
    "    mergedYear = addTime(df)\n",
    "    \n",
    "    mergedYear = mergedYear.rename(columns={'totalEdits': new_column_name})\n",
    "    \n",
    "    \n",
    "    return mergedYear\n",
    "\n",
    "# combined table for the corrected timeframe - f first, m middle, l last\n",
    "def df_timeframes_merged(db, CEwhere_statment, nonCEwhere_statment, corporate_list, f, m, l):\n",
    "\n",
    "    CE_edits = Edits_monthly(db, CEwhere_statment, corporate_list, 'CE')\n",
    "    nonCE_edits = Edits_monthly(db, nonCEwhere_statment, corporate_list, 'NCE')\n",
    "\n",
    "    total_tf = pd.merge(nonCE_edits, CE_edits, how=\"outer\", on=['name', 'time'])\n",
    "\n",
    "    tf_total = total_tf.loc[(total_tf['time'] >= f) & (total_tf['time'] <= l)].reset_index(drop=True)\n",
    "\n",
    "    tf_pre = total_tf.loc[(total_tf['time'] >= f) & (total_tf['time'] <= m)].reset_index(drop=True)\n",
    "    tf_post = total_tf.loc[(total_tf['time'] > m) & (total_tf['time'] <= l)].reset_index(drop=True)  \n",
    "    \n",
    "\n",
    "    return tf_total, tf_pre, tf_post\n",
    "\n",
    "# calculating mean and median values \n",
    "def calculating_columns(calc_type, df, name_column, new_column_name):\n",
    "    if calc_type == 'mean':\n",
    "        result = df[[name_column, 'name']].groupby('name').mean().reset_index()\n",
    "        result = result.rename(columns={name_column: new_column_name})\n",
    "        return result\n",
    "\n",
    "    elif calc_type == 'median':\n",
    "        result = df[[name_column, 'name']].groupby('name').median().reset_index()\n",
    "        result = result.rename(columns={name_column: new_column_name})\n",
    "        return result\n",
    "\n",
    "    else:\n",
    "        print('error: neither mean nor median as input')\n",
    "\n",
    "\n",
    "# combined table for the mean and median values \n",
    "def calculate_median_mean_combitable(db, CEwhere_statment, nonCEwhere_statment, corporate_list, f, m, l):\n",
    "\n",
    "    df_total, df_pre, df_post = df_timeframes_merged(db, CEwhere_statment, nonCEwhere_statment, corporate_list, f, m, l)\n",
    "\n",
    "    # non-corporate median for t0\n",
    "    pre_corpo_nc_median = calculating_columns('median', df_pre, 'NCE', 't0_nc_median')\n",
    "    \n",
    "    # non-corporate median for t1\n",
    "    post_corpo_nc_median = calculating_columns('median', df_post, 'NCE', 't1_nc_median')\n",
    "\n",
    "    #corporate median for t0\n",
    "    pre_corpo_c_median = calculating_columns('median', df_pre, 'CE', 't0_c_median')\n",
    "\n",
    "    # corporate median for t1\n",
    "    post_corpo_c_median = calculating_columns('median', df_post, 'CE', 't1_c_median')\n",
    "\n",
    "\n",
    "    # non-corporate mean for t0\n",
    "    pre_corpo_nc_mean = calculating_columns('mean', df_pre, 'NCE', 't0_nc_mean')\n",
    "    \n",
    "    # non-corporate mean for t1\n",
    "    post_corpo_nc_mean = calculating_columns('mean', df_post, 'NCE', 't1_nc_mean')\n",
    "\n",
    "    #corporate mean for t0\n",
    "    pre_corpo_c_mean = calculating_columns('mean', df_pre, 'CE', 't0_c_mean')\n",
    "\n",
    "    # corporate mean for t1\n",
    "    post_corpo_c_mean = calculating_columns('mean', df_post, 'CE', 't1_c_mean')\n",
    "\n",
    "\n",
    "    merged_table = pd.merge(pre_corpo_nc_median, post_corpo_nc_median, on = 'name', how = 'outer')\n",
    "    merged_table = pd.merge(merged_table, pre_corpo_c_median, on = 'name', how = 'outer')\n",
    "    merged_table = pd.merge(merged_table, post_corpo_c_median, on = 'name', how = 'outer')\n",
    "    merged_table = pd.merge(merged_table, pre_corpo_nc_mean, on = 'name', how = 'outer')\n",
    "    merged_table = pd.merge(merged_table, post_corpo_nc_mean, on = 'name', how = 'outer')\n",
    "    merged_table = pd.merge(merged_table, pre_corpo_c_mean, on = 'name', how = 'outer')\n",
    "    merged_table = pd.merge(merged_table, post_corpo_c_mean, on = 'name', how = 'outer')\n",
    "\n",
    "    return merged_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f278a5c-d530-495b-a202-acfafbe38943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the timeframe\n",
    "first = str('06-2019')\n",
    "last = str('05-2023')\n",
    "middle = str('05-2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c0aa64-024d-4cc7-932f-65e1a0f3cb73",
   "metadata": {},
   "source": [
    "### United Arab Emirates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddece3d2-dfaf-4a21-b43c-14c4cc1c0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpolist_are = duckdb.sql(f\"\"\"\n",
    "    SELECT distinct h3_cell_id\n",
    "    FROM are\n",
    "    WHERE ({meta_where_corpo})\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "corpolist_are.fetchall()\n",
    "\n",
    "corpolist_are = corpolist_are.to_df()\n",
    "cl_are = corpolist_are.dropna()\n",
    "a_corporate_list = cl_are['h3_cell_id'].tolist()\n",
    "\n",
    "# workable lists for the cell ids with corporate edits\n",
    "corporate_list_are = create_string(cl_are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521dd38-4382-42de-9c2c-6e9695227f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "are_meta = calculate_median_mean_combitable('are',meta_where_corpo, meta_where_non_corpo,corporate_list_are, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ff6668f-9900-4fcf-b740-3429293c89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "are_meta.to_csv('are_mean_median_meta_hex_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "923a1bcb-d1f7-43bd-b110-0e539424c94f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>t0_nc_median</th>\n",
       "      <th>t1_nc_median</th>\n",
       "      <th>t0_c_median</th>\n",
       "      <th>t1_c_median</th>\n",
       "      <th>t0_nc_mean</th>\n",
       "      <th>t1_nc_mean</th>\n",
       "      <th>t0_c_mean</th>\n",
       "      <th>t1_c_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86438415fffffff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8643841afffffff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86438442fffffff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864384507ffffff</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864384537ffffff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>86534dcc7ffffff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>86534dcdfffffff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>86534dce7ffffff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>86534dcf7ffffff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>86534dd07ffffff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1515 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  t0_nc_median  t1_nc_median  t0_c_median  t1_c_median  \\\n",
       "0     86438415fffffff           1.0           1.0          1.0          2.5   \n",
       "1     8643841afffffff           NaN           NaN          1.0          NaN   \n",
       "2     86438442fffffff           1.0           NaN          1.0          NaN   \n",
       "3     864384507ffffff           3.0           NaN          2.0          NaN   \n",
       "4     864384537ffffff           1.0           NaN          1.0          NaN   \n",
       "...               ...           ...           ...          ...          ...   \n",
       "1510  86534dcc7ffffff           NaN           4.0          NaN          5.0   \n",
       "1511  86534dcdfffffff           NaN           1.0          NaN          5.0   \n",
       "1512  86534dce7ffffff           NaN           NaN          NaN          1.0   \n",
       "1513  86534dcf7ffffff           NaN           1.0          NaN          1.0   \n",
       "1514  86534dd07ffffff           NaN           1.0          NaN         24.0   \n",
       "\n",
       "      t0_nc_mean  t1_nc_mean  t0_c_mean  t1_c_mean  \n",
       "0            1.0         1.0        1.0   2.500000  \n",
       "1            NaN         NaN        1.0        NaN  \n",
       "2            1.0         NaN        1.0        NaN  \n",
       "3            3.0         NaN        2.0        NaN  \n",
       "4            1.0         NaN        1.0        NaN  \n",
       "...          ...         ...        ...        ...  \n",
       "1510         NaN         4.0        NaN   5.000000  \n",
       "1511         NaN         9.0        NaN  12.666667  \n",
       "1512         NaN         NaN        NaN   1.000000  \n",
       "1513         NaN         1.0        NaN   8.333333  \n",
       "1514         NaN         1.0        NaN  24.000000  \n",
       "\n",
       "[1515 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "are_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3489b14f-b279-418d-84a9-b7348f094892",
   "metadata": {},
   "source": [
    "### Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4172a552-070d-42e4-bd1c-a6a2509bedf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpolist_col = duckdb.sql(f\"\"\"\n",
    "    SELECT distinct h3_cell_id\n",
    "    FROM col\n",
    "    WHERE ({meta_where_corpo})\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "corpolist_col.fetchall()\n",
    "\n",
    "corpolist_col = corpolist_col.to_df()\n",
    "cl_col = corpolist_col.dropna()\n",
    "a_corporate_list = cl_col['h3_cell_id'].tolist()\n",
    "\n",
    "# workable lists for the cell ids with corporate edits\n",
    "corporate_list_col = create_string(cl_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ef008e8-9df8-41c4-bd70-0e021c39d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_df = corpolist_col.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f7947b4-892a-4fde-93d8-ea864b5f835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run as batch process\n",
    "n = 2000  #chunk row size\n",
    "list_df_col = [col_df[i:i+n] for i in range(0,col_df.shape[0],n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "117a9f46-992a-4609-8e47-a93493ad7347",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_corpo_list_1 = create_string(list_df_col[0].dropna())\n",
    "col_corpo_list_2 = create_string(list_df_col[1].dropna())\n",
    "col_corpo_list_3 = create_string(list_df_col[2].dropna())\n",
    "col_corpo_list_4 = create_string(list_df_col[3].dropna())\n",
    "col_corpo_list_5 = create_string(list_df_col[4].dropna())\n",
    "col_corpo_list_6 = create_string(list_df_col[5].dropna())\n",
    "col_corpo_list_7 = create_string(list_df_col[6].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "199bbf27-a86b-42ab-90a0-763aee059374",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = calculate_median_mean_combitable('col', meta_where_corpo, meta_where_non_corpo, col_corpo_list_1, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a046e11-d435-4b51-a4bb-237b6169ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = calculate_median_mean_combitable('col', meta_where_corpo, meta_where_non_corpo, col_corpo_list_2, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b43f0199-d275-4c25-97b0-4e592f0ecbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = calculate_median_mean_combitable('col', meta_where_corpo, meta_where_non_corpo, col_corpo_list_3, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4f4eebd-b1c9-4f66-81c6-9a2ac62ce0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c4 = calculate_median_mean_combitable('col', meta_where_corpo, meta_where_non_corpo, col_corpo_list_4, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58d5ba2b-b8cf-4eab-a2d7-958de80d5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c5 = calculate_median_mean_combitable('col', meta_where_corpo, meta_where_non_corpo, col_corpo_list_5, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "919a44cd-51f3-41d3-aefa-c292f06d18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c6 = calculate_median_mean_combitable('col', meta_where_corpo, meta_where_non_corpo, col_corpo_list_6, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22dfbffc-e76e-457e-ae38-b3a091a08681",
   "metadata": {},
   "outputs": [],
   "source": [
    "c7 = calculate_median_mean_combitable('col', meta_where_corpo, meta_where_non_corpo, col_corpo_list_7, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21c2b8e4-0b93-4797-a34d-2445826f3ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [c1, c2, c3, c4, c5, c6, c7]\n",
    "\n",
    "col_meta_result = pd.concat(frames)\n",
    "col_meta_result.to_csv(\"col_mean_median_meta_hex_v2.csv\", header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eea2b8-e162-4f43-a387-28fded2a4a79",
   "metadata": {},
   "source": [
    "### Indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94f4ec88-59c0-455f-bd06-6cf27ad95e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpolist_idn = duckdb.sql(f\"\"\"\n",
    "    SELECT distinct h3_cell_id\n",
    "    FROM idn\n",
    "    WHERE ({meta_where_corpo})\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "corpolist_idn.fetchall()\n",
    "\n",
    "corpolist_idn = corpolist_idn.to_df()\n",
    "cl_idn = corpolist_idn.dropna()\n",
    "a_corporate_list = cl_idn['h3_cell_id'].tolist()\n",
    "\n",
    "# workable lists for the cell ids with corporate edits\n",
    "corporate_list_idn = create_string(cl_idn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74165a02-4db9-45ff-bce7-e977c2449131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idn = corpolist_idn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ec376b1-93a7-4fdf-8a71-5ae064335557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run as batch process\n",
    "n = 2000  #chunk row size\n",
    "list_df_idn = [df_idn[i:i+n] for i in range(0,df_idn.shape[0],n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bb7ee57-07b6-47ac-8fec-3fb686bf7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idn_corpo_list_1 = create_string(list_df_idn[0].dropna())\n",
    "idn_corpo_list_2 = create_string(list_df_idn[1].dropna())\n",
    "idn_corpo_list_3 = create_string(list_df_idn[2].dropna())\n",
    "idn_corpo_list_4 = create_string(list_df_idn[3].dropna())\n",
    "idn_corpo_list_5 = create_string(list_df_idn[4].dropna())\n",
    "idn_corpo_list_6 = create_string(list_df_idn[5].dropna())\n",
    "idn_corpo_list_7 = create_string(list_df_idn[6].dropna())\n",
    "idn_corpo_list_8 = create_string(list_df_idn[7].dropna())\n",
    "idn_corpo_list_9 = create_string(list_df_idn[8].dropna())\n",
    "idn_corpo_list_10 = create_string(list_df_idn[9].dropna())\n",
    "idn_corpo_list_11 = create_string(list_df_idn[10].dropna())\n",
    "idn_corpo_list_12 = create_string(list_df_idn[11].dropna())\n",
    "idn_corpo_list_13 = create_string(list_df_idn[12].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79403dc1-05e5-4432-a825-bd06e797da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = calculate_median_mean_combitable('idn', meta_where_corpo, meta_where_non_corpo, idn_corpo_list_1, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38e92268-0c1f-4b38-9eb8-27db3d12166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2 = calculate_median_mean_combitable('idn',meta_where_corpo, meta_where_non_corpo, idn_corpo_list_2, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff1698f7-170d-4563-92f0-358c641b8945",
   "metadata": {},
   "outputs": [],
   "source": [
    "i3 = calculate_median_mean_combitable('idn',meta_where_corpo, meta_where_non_corpo, idn_corpo_list_3, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0af875d4-858e-4580-a80c-07e17e1bb5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i4 = calculate_median_mean_combitable('idn',meta_where_corpo, meta_where_non_corpo, idn_corpo_list_4, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7ffc0cd-d8d2-4c95-a801-0b83f32eb288",
   "metadata": {},
   "outputs": [],
   "source": [
    "i5 = calculate_median_mean_combitable('idn',meta_where_corpo, meta_where_non_corpo, idn_corpo_list_5, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec10e495-d3d5-402e-a0e8-bcba37177ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "i6 = calculate_median_mean_combitable('idn',meta_where_corpo, meta_where_non_corpo, idn_corpo_list_6, first, middle, last)\n",
    "i7 = calculate_median_mean_combitable('idn',meta_where_corpo, meta_where_non_corpo, idn_corpo_list_7, first, middle, last)\n",
    "i8 = calculate_median_mean_combitable('idn',meta_where_corpo, meta_where_non_corpo, idn_corpo_list_8, first, middle, last)\n",
    "i9 = calculate_median_mean_combitable('idn',meta_where_corpo, meta_where_non_corpo, idn_corpo_list_9, first, middle, last)\n",
    "i10 = calculate_median_mean_combitable('idn',meta_where_corpo, meta_where_non_corpo, idn_corpo_list_10, first, middle, last)\n",
    "i11 = calculate_median_mean_combitable('idn',meta_where_corpo, meta_where_non_corpo, idn_corpo_list_11, first, middle, last)\n",
    "i12 = calculate_median_mean_combitable('idn',meta_where_corpo, meta_where_non_corpo, idn_corpo_list_12, first, middle, last)\n",
    "i13 = calculate_median_mean_combitable('idn',meta_where_corpo, meta_where_non_corpo, idn_corpo_list_13, first, middle, last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "122bbc1c-20e3-4bb7-bbed-cde9f05471f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11, i12, i13]\n",
    "\n",
    "idn_result = pd.concat(frames)\n",
    "idn_result.to_csv(\"idn_combi_table_result_meta_v2.csv\", header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
